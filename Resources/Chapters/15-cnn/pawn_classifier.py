# -*- coding: utf-8 -*-
"""pawn_classifier

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RrElXBONJLEC575_coh6yIGTSzEad-An
"""

# import necessary libraries
import numpy as np
import imutils
import cv2
import pandas as pd
import zipfile
from google.colab import files
import io
import os
import zipfile
from PIL import ImageDraw,Image,ImageFont
from google.colab.patches import cv2_imshow

# zip_file = '/content/pawn_dataset.zip'
# zip_ref = zipfile.ZipFile(zip_file,'r')
# zip_ref.extractall('/content')
# zip_ref.close()

# annotations = pd.read_csv('/content/pawn_dataset.csv')

# annotations.head

import tensorflow as tf

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator

chess_data = os.path.join('/content/content/pawn_dataset')
data = ImageDataGenerator(validation_split=0.2,rescale=1./255,
        rotation_range=40,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest')

# index = 0
# for i, row in annotations.iterrows():
#   pic_name = row['Name']
#   image = cv2.imread('/content/content/data/pawn_classification_dataset/'+pic_name)
#   if(row['Label']=="pawn"):
#     cv2.imwrite("/content/pawn_dataset/pawn/pic{}".format(str(index)+".jpg"),image)
#   else:
#     cv2.imwrite("/content/pawn_dataset/not pawn/pic{}".format(str(index)+".jpg"),image)
#   index = index+1

pawn_train_dir = data.flow_from_directory(chess_data,subset='training',batch_size = 20,class_mode='binary',target_size=(150,150))
pawn_valid_dir = data.flow_from_directory(chess_data,subset='validation',batch_size = 20,class_mode='binary',target_size=(150,150))

x,y=pawn_train_dir.next()
x.shape

# from tensorflow.keras.regularizers import l2
from tensorflow.keras.layers import Activation


model = Sequential()
model.add(Conv2D(32, (3, 3), input_shape=(150, 150,3),padding='same'))
model.add(Activation('relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(32, (3, 3),padding='same'))
model.add(Activation('relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(64, (3, 3),padding='same'))
model.add(Activation('relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors

model.add(Dense(64))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(1))
model.add(Activation('sigmoid'))

from tensorflow.keras.optimizers import RMSprop, SGD, Adam
# model.compile(optimizer=RMSprop(lr=0.01),loss='binary_crossentropy',metrics=['acc'])
model.compile(optimizer=SGD(lr=0.01),loss='binary_crossentropy',metrics=['acc'])

history = model.fit_generator(epochs=10,generator=pawn_train_dir,validation_data=pawn_valid_dir,verbose=1)



